# Extract, Transform, Load

## Overview
The purpose of this challenge is to follow the ETL process to prepare large datasets for analyzing.  
The steps for ETL is as follows:
1. Extract data from Wikipedia and Kaggle.
2. Transform the datasets via function data cleaning and mergining.
3. Load the final cleaned dataset into a SQL database

## Resources
- Data Source: Click [Here](https://github.com/junepwk/movies-ETL/tree/main/Resources)
- Softward: pgAdmin 4 v5.2, Jupyter Notebook 6.3.0, Python 3.7.10
